{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "western-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "from utils.helper_metastore import *\n",
    "from utils.configurations.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sapphire-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'absl')\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-refund",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-custom",
   "metadata": {},
   "source": [
    "Here comes the most important part of our pipeline (model training). The whole pipeline that we are trying to build on are jointly called as an Continous training component in the MLOps workflow. The main moto over here is to keep our model upto date in the production and the counter back the data drift, model drift and training-serving skew.\n",
    "\n",
    "![mlops pipeline](image/MLOps_pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-bankruptcy",
   "metadata": {},
   "source": [
    "In this notebook, we cover the model training process as part of a machine learning pipeline, including how it is automated in a TFX pipeline. We also include some details of distribution strategies available in TensorFlow and how to tune hyperparameters in a pipeline. This chapter is more specific to TFX pipelines than most of the\n",
    "others because we don’t cover training as a standalone process.\n",
    "\n",
    "One very important feature of training a model in a TFX pipeline is that the data pre-processing step which ar saved along with the trained model weights. This is very useful once our model is deployed to production because it means that the preprocessing steps will always produce the features the models expecting. Without this feature, it would be possible to update the data pre‐processing steps without updating the model, and then the model would fail in production. So why TFX eports the proprocessing steps and the model as one graph, this potentialy eliminates the source of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-laugh",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-parking",
   "metadata": {},
   "source": [
    "In this session, let assume we create some model which was trained as offline experimentation. we then decided to productionize it with the MLOps worflow. In this pipeline step, we want to export the model with our preprocessing steps, we need to guarantee that the model input names match the transformed feature names from ```preprocessing_fn()```. In our example model, we reuse the ```transformed_name()``` function to add the suffix _xf to our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romantic-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "def transformed_name(key):\n",
    "    return key + '_xf'\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    LABEL_KEY = \"consumer_disputed\"\n",
    "    # Loop over the features and create an input for each feature.\n",
    "    # Feature name, feature dimensionality.\n",
    "    ONE_HOT_FEATURES = {\n",
    "    \"product\": 11,\n",
    "    \"sub_product\": 45,\n",
    "    \"company_response\": 5,\n",
    "    \"state\": 60,\n",
    "    \"issue\": 90\n",
    "    }\n",
    "\n",
    "    # Feature name, bucket count.\n",
    "    BUCKET_FEATURES = {\n",
    "    \"zip_code\": 10\n",
    "    }\n",
    "\n",
    "    # Feature name, value is unused.\n",
    "    TEXT_FEATURES = {\n",
    "    \"consumer_complaint_narrative\": None\n",
    "    }\n",
    "    # One-hot categorical features\n",
    "    input_features = []\n",
    "    for key, dim in ONE_HOT_FEATURES.items():\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(dim + 1,),\n",
    "            name=transformed_name(key)))\n",
    "        \n",
    "    # Adding bucketized features\n",
    "    for key, dim in BUCKET_FEATURES.items():\n",
    "        input_features.append(\n",
    "            tf.keras.Input(shape=(dim + 1,),\n",
    "            name=transformed_name(key)))\n",
    "    \n",
    "    # Adding text input features\n",
    "    input_texts = []\n",
    "    for key in TEXT_FEATURES.keys():\n",
    "        input_texts.append(\n",
    "            tf.keras.Input(shape=(1,),\n",
    "            name=transformed_name(key),\n",
    "            dtype=tf.string))\n",
    "    \n",
    "    inputs = input_features + input_texts\n",
    "    # Embed text features\n",
    "    # Load the tf.hub module of the Universal Sentence Encoder model.\n",
    "    MODULE_URL = \n",
    "    embed = hub.KerasLayer(MODULE_URL)\n",
    "    \n",
    "    reshaped_narrative = tf.reshape(input_texts[0], [-1]) # Keras inputs are two-dimensional, \n",
    "                                                            # but the encoder expects one-dimensional inputs.\n",
    "    embed_narrative = embed(reshaped_narrative)\n",
    "    deep_ff = tf.keras.layers.Reshape((512, ), input_shape=(1, 512))(embed_narrative)\n",
    "    deep = tf.keras.layers.Dense(256, activation='relu')(deep_ff)\n",
    "    deep = tf.keras.layers.Dense(64, activation='relu')(deep)\n",
    "    deep = tf.keras.layers.Dense(16, activation='relu')(deep)\n",
    "    wide_ff = tf.keras.layers.concatenate(input_features)\n",
    "    wide = tf.keras.layers.Dense(16, activation='relu')(wide_ff)\n",
    "    both = tf.keras.layers.concatenate([deep, wide])\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
    "    keras_model = tf.keras.models.Model(inputs, output)\n",
    "    keras_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "    tf.keras.metrics.BinaryAccuracy(),\n",
    "    tf.keras.metrics.TruePositives()\n",
    "    ])\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yellow-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model()\n",
    "\n",
    "embedding = hub.KerasLayer('../models/universal-sentence-encoder_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "substantial-canberra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[-5.73915504e-02, -1.82517227e-02,  5.40610440e-02,\n",
       "        -1.05629796e-02,  5.26848733e-02, -1.70335826e-02,\n",
       "         4.58819084e-02, -6.38231784e-02,  1.02628479e-02,\n",
       "         5.89594841e-02,  3.36269476e-02,  2.78246552e-02,\n",
       "        -5.38831130e-02,  8.77926778e-03,  2.70789620e-02,\n",
       "        -7.52516165e-02, -4.78043370e-02,  1.69670079e-02,\n",
       "        -4.39201556e-02, -6.64973035e-02,  9.78493690e-02,\n",
       "        -2.02894080e-02,  3.17293359e-03,  1.30768614e-02,\n",
       "        -6.03378750e-02,  2.25895438e-02,  4.08571921e-02,\n",
       "         5.44126444e-02, -2.88982093e-02,  3.93695123e-02,\n",
       "         5.40930815e-02,  1.13724852e-02,  3.97175103e-02,\n",
       "        -1.39451139e-02, -3.05868089e-02, -1.02045918e-02,\n",
       "        -5.70705626e-04, -3.76856588e-02,  6.99091610e-03,\n",
       "        -1.82859716e-03,  3.30865309e-02,  2.19007153e-02,\n",
       "         2.42540464e-02,  5.49291223e-02,  4.06780802e-02,\n",
       "        -7.57424568e-05, -9.26447138e-02,  2.11828724e-02,\n",
       "         3.29384543e-02,  2.71808878e-02, -3.48641053e-02,\n",
       "         1.21699877e-01, -9.97217372e-03, -3.06700878e-02,\n",
       "        -2.28577442e-02,  1.58736687e-02, -4.47357446e-02,\n",
       "        -8.60307366e-03,  1.34906610e-02,  4.26165611e-02,\n",
       "         1.50500080e-02, -1.89925022e-02,  6.06339797e-02,\n",
       "         6.15839399e-02,  4.45087701e-02,  1.80644784e-02,\n",
       "         6.44016340e-02, -1.42277814e-02,  5.03414683e-02,\n",
       "        -6.79021096e-03, -9.97418258e-03,  3.72655243e-02,\n",
       "         2.64811646e-02, -6.12882562e-02, -5.66618517e-02,\n",
       "         3.75189632e-02, -4.26460914e-02,  5.83003275e-03,\n",
       "         3.26802656e-02, -1.15329042e-01, -3.97143997e-02,\n",
       "         2.59113535e-02, -9.74872261e-02, -3.07295714e-02,\n",
       "        -3.59644257e-02, -8.78220797e-02, -3.85580957e-02,\n",
       "         4.03740145e-02, -2.60084998e-02,  5.94277084e-02,\n",
       "        -4.64745723e-02,  8.13233405e-02,  1.94548797e-02,\n",
       "        -1.37650697e-02, -2.35692598e-02, -4.47071157e-02,\n",
       "        -3.19060236e-02,  1.12485968e-01, -6.64576367e-02,\n",
       "        -3.40538323e-02,  1.17856255e-02,  1.81266814e-02,\n",
       "         8.61898959e-02, -5.95705875e-04,  2.50273310e-02,\n",
       "        -7.74046313e-03,  6.91196844e-02,  7.29598030e-02,\n",
       "        -3.88326240e-03,  3.51654664e-02, -6.49545668e-03,\n",
       "         3.28881033e-02, -8.76456723e-02, -7.34700263e-02,\n",
       "         6.42701611e-02,  5.19339275e-03,  6.65665371e-03,\n",
       "        -3.18427337e-03, -1.44353509e-02, -9.44958255e-03,\n",
       "         4.56636064e-02,  3.70091759e-02, -5.72855435e-02,\n",
       "         1.60576217e-02, -5.97066395e-02, -4.15313654e-02,\n",
       "         3.62710208e-02,  4.51081945e-03,  6.94882646e-02,\n",
       "         4.86392416e-02,  2.35885307e-02, -1.24510778e-02,\n",
       "         3.23677026e-02,  3.62558328e-02, -5.72236702e-02,\n",
       "        -5.02167307e-02, -4.80623357e-02, -6.13055453e-02,\n",
       "         9.31216627e-02,  1.66065767e-02,  3.48684601e-02,\n",
       "        -3.63384038e-02,  6.98608011e-02, -3.13232280e-02,\n",
       "         1.57204792e-02, -4.05048132e-02,  1.02106882e-02,\n",
       "        -2.33619139e-02, -2.39634290e-02,  5.10953590e-02,\n",
       "         5.28756641e-02,  1.01257879e-02,  1.75487977e-02,\n",
       "         3.04079801e-02, -3.95544954e-02, -6.66572824e-02,\n",
       "        -3.57996742e-03,  1.15005627e-01, -2.04365817e-03,\n",
       "        -9.16839205e-03, -2.98220627e-02, -2.74109561e-02,\n",
       "        -4.59969155e-02, -2.33737882e-02, -1.53066954e-02,\n",
       "         3.18731298e-03, -2.30597910e-02, -4.07022387e-02,\n",
       "         2.90886983e-02, -5.89621402e-02,  8.07448849e-02,\n",
       "         4.76223230e-02, -3.24583314e-02,  3.56349349e-02,\n",
       "        -7.11155906e-02, -5.83643056e-02, -3.11158621e-03,\n",
       "        -2.97217295e-02,  7.38242548e-03, -4.02243137e-02,\n",
       "         3.60374376e-02, -3.81104276e-02,  4.14100140e-02,\n",
       "        -5.88791147e-02, -3.10377162e-02, -7.25357011e-02,\n",
       "         1.65642202e-02, -4.43240367e-02,  1.52863027e-03,\n",
       "        -3.76220830e-02,  2.51255985e-02,  7.10788881e-03,\n",
       "         6.82147592e-02,  5.88516854e-02, -1.40208481e-02,\n",
       "         4.94284779e-02, -1.22540537e-03, -2.06945091e-03,\n",
       "         2.34786924e-02, -1.11801997e-02,  2.43024137e-02,\n",
       "        -6.65318146e-02,  1.80555265e-02, -5.94559275e-02,\n",
       "        -5.17528467e-02,  1.44642293e-02,  2.84413490e-02,\n",
       "         4.86220010e-02,  7.11906422e-03, -2.31021289e-02,\n",
       "         4.59806807e-02, -1.20409550e-02,  4.45703156e-02,\n",
       "         1.80359092e-02, -2.39853617e-02, -2.78314110e-03,\n",
       "        -9.25403088e-03, -1.18734486e-01, -3.91827188e-02,\n",
       "         4.07723188e-02, -8.89311731e-03,  1.59406941e-02,\n",
       "        -4.18419018e-02,  4.30182777e-02, -5.27277701e-02,\n",
       "         4.20800038e-02,  2.86824796e-02,  8.17732736e-02,\n",
       "        -6.06596330e-03,  1.88652836e-02, -1.00624049e-02,\n",
       "         6.67772442e-02, -2.49656383e-03,  1.21466361e-01,\n",
       "         5.90842264e-03, -1.02898102e-05, -7.83636346e-02,\n",
       "         4.55683842e-02,  8.67302343e-03,  5.91209829e-02,\n",
       "        -9.69557911e-02, -4.50613834e-02, -1.07716992e-02,\n",
       "        -3.06128263e-02, -3.36509719e-02,  1.10337429e-01,\n",
       "        -1.29774737e-03, -4.80556302e-02,  1.20958686e-01,\n",
       "        -6.74199685e-02,  4.28531021e-02, -1.33702997e-03,\n",
       "         1.30971968e-02,  7.28251934e-02,  1.17721066e-01,\n",
       "        -4.29668054e-02,  3.44319120e-02,  2.37093903e-02,\n",
       "         2.14811247e-02, -3.00865574e-03,  1.31657987e-03,\n",
       "         2.88001522e-02, -1.04876146e-01,  5.81094362e-02,\n",
       "        -7.52472319e-03,  2.75109205e-02, -2.86289137e-02,\n",
       "        -1.16856359e-01,  8.04390851e-03, -3.06845400e-02,\n",
       "         4.96630818e-02,  9.93776098e-02,  7.96870235e-03,\n",
       "         8.12732205e-02, -8.14939197e-03,  4.85437848e-02,\n",
       "         1.61127709e-02,  6.52431995e-02, -9.22849402e-03,\n",
       "         5.11359237e-02, -6.51881378e-03, -2.31312085e-02,\n",
       "         6.63742190e-03, -3.82208452e-02,  3.73447835e-02,\n",
       "         4.04010862e-02,  7.17996107e-03, -1.37750851e-02,\n",
       "        -3.63916755e-02,  3.92320529e-02,  1.40121290e-02,\n",
       "         2.58389078e-02, -6.86435252e-02,  4.17676568e-02,\n",
       "        -2.07575504e-02,  2.27005896e-03,  3.89134958e-02,\n",
       "         2.26418916e-02,  3.05224936e-02,  5.24950698e-02,\n",
       "         1.89383626e-02,  5.13035357e-02, -8.20353478e-02,\n",
       "        -9.11020041e-02, -1.20856604e-02,  6.32438511e-02,\n",
       "         3.71572562e-02,  8.61267908e-04,  5.99620566e-02,\n",
       "         2.59253997e-02, -1.25352722e-02,  1.63820516e-02,\n",
       "        -2.11431496e-02, -1.19663505e-02,  2.66743470e-02,\n",
       "         7.94545189e-02,  6.03271797e-02,  3.16810608e-02,\n",
       "        -3.39658596e-02, -1.33214863e-02, -4.00069989e-02,\n",
       "         3.62531506e-02,  3.22590508e-02, -1.65736899e-02,\n",
       "         6.01643138e-02,  5.67517541e-02,  2.41193175e-02,\n",
       "         1.38489893e-02, -1.54690240e-02,  1.46322101e-02,\n",
       "         2.90569849e-02, -1.55947851e-02,  2.47438606e-02,\n",
       "         1.47216916e-02, -5.52182198e-02, -4.68282849e-02,\n",
       "         6.89643994e-02,  3.11874878e-02,  3.43952850e-02,\n",
       "        -3.64573337e-02,  2.47267671e-02, -5.99326342e-02,\n",
       "        -3.87716256e-02,  5.50679006e-02, -1.58049390e-02,\n",
       "        -1.33363632e-02, -2.19489299e-02, -3.44354957e-02,\n",
       "         1.32796606e-02, -1.45778721e-02,  4.24621190e-04,\n",
       "        -4.39441428e-02, -1.67359021e-02, -7.00463355e-02,\n",
       "        -3.88799198e-02,  1.87522080e-02, -1.04492046e-01,\n",
       "         1.14499610e-02,  5.12066260e-02,  2.24864893e-02,\n",
       "        -4.69562858e-02, -2.61526406e-02,  4.91617247e-02,\n",
       "         5.93842492e-02, -8.03858507e-03,  6.29646480e-02,\n",
       "        -6.99682757e-02, -3.49937826e-02, -4.03582584e-03,\n",
       "        -4.48563248e-02, -1.60227958e-02, -1.65612511e-02,\n",
       "         2.82224249e-02,  2.26051938e-02, -1.39628286e-02,\n",
       "         1.21013351e-01,  2.20630318e-02, -4.23737802e-02,\n",
       "         9.20257419e-02, -3.52882333e-02, -7.49840075e-03,\n",
       "        -2.29640845e-02,  3.22187468e-02,  3.94593142e-02,\n",
       "        -7.05451369e-02,  4.66810726e-02, -1.91567615e-02,\n",
       "         4.71332436e-03,  2.33744700e-02,  5.28081879e-02,\n",
       "         7.85607249e-02, -1.76555682e-02,  5.55780008e-02,\n",
       "         2.34976094e-02,  5.92903234e-03, -2.95189656e-02,\n",
       "        -8.89645051e-03, -4.16757427e-02,  4.44300994e-02,\n",
       "         8.99403542e-02,  3.07564624e-02,  4.56601419e-02,\n",
       "        -5.14459051e-02, -6.02670666e-03, -6.35438878e-03,\n",
       "         2.24206708e-02, -2.49626320e-02, -3.93500878e-03,\n",
       "         3.70309949e-02, -6.00724295e-02, -9.12025943e-02,\n",
       "         2.02177390e-02,  2.05670688e-02,  1.32956533e-02,\n",
       "        -1.88888721e-02,  9.75531340e-03, -6.68477314e-03,\n",
       "         6.49565905e-02,  3.94702237e-03,  2.61499453e-02,\n",
       "        -5.35971485e-02,  2.02210173e-02, -5.50848283e-02,\n",
       "        -3.67364436e-02,  2.93171741e-02,  7.00468794e-02,\n",
       "         2.67173462e-02,  6.38912469e-02, -4.36776988e-02,\n",
       "         5.02812527e-02, -4.81426343e-02,  4.08303738e-02,\n",
       "        -6.75182045e-02, -2.43383236e-02, -1.53966574e-02,\n",
       "        -2.79718209e-02,  9.27956402e-02,  1.35035887e-02,\n",
       "        -2.51980918e-03,  3.78069542e-02,  6.10068105e-02,\n",
       "         1.80861615e-02,  5.47954999e-02,  2.92303916e-02,\n",
       "         3.79799083e-02,  8.94351304e-03,  4.70064627e-03,\n",
       "        -2.57997643e-02, -2.59660650e-02, -2.70275902e-02,\n",
       "         3.55806164e-02, -4.20373380e-02, -9.66054574e-03,\n",
       "        -3.40115428e-02, -3.78170721e-02,  3.02087690e-04,\n",
       "        -3.99983190e-02, -4.97469567e-02, -1.36383495e-03,\n",
       "        -4.10851277e-03,  2.50080172e-02, -4.93301786e-02,\n",
       "         9.09604132e-03, -1.02133960e-01,  3.65452319e-02,\n",
       "        -6.10488839e-02,  9.49221011e-03, -1.52480637e-03,\n",
       "         3.06184627e-02, -9.65101528e-04,  3.68869342e-02,\n",
       "         3.91261578e-02,  3.11460719e-02, -2.03684699e-02,\n",
       "        -2.40877476e-02, -2.31789481e-02, -2.45488132e-03,\n",
       "         4.61274907e-02, -1.60055552e-02,  7.88672566e-02,\n",
       "        -4.60591055e-02,  1.18452124e-02,  6.97600609e-03,\n",
       "        -2.24934309e-03,  1.51132606e-02,  7.02122822e-02,\n",
       "         1.82824936e-02, -4.45381701e-02, -4.45105787e-03,\n",
       "        -4.38614422e-03, -4.62315716e-02, -6.79559186e-02,\n",
       "        -4.43835892e-02, -7.76083395e-03, -5.69675304e-02,\n",
       "         2.84869224e-03, -4.62068543e-02, -2.54938696e-02,\n",
       "         1.00737490e-01,  2.23385356e-02, -2.39755996e-02,\n",
       "        -7.16139656e-03, -8.18373635e-02,  5.31820357e-02,\n",
       "         1.27313817e-02,  7.09317066e-03, -1.65147018e-02,\n",
       "        -4.48393486e-02, -2.22069006e-02,  5.44141233e-03,\n",
       "        -8.39538034e-03,  2.12707580e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
