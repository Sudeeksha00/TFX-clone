{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-demographic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/dataset1\n",
    "mkdir -p ../data/dataset2\n",
    "\n",
    "python3 ../utils/download_dataset.py\n",
    "python3 ../utils/convert_to_tfrecords.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "from utils.configurations.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-scottish",
   "metadata": {},
   "source": [
    "# Content of the Table\n",
    "\n",
    ">- [Data Ingestion](#Data-Ingestion)\n",
    ">-[ What is InteractiveContext?](#What-is-InteractiveContext?)\n",
    ">-[Output of the component](#Output-of-the-component)\n",
    ">-[what metadata store is for?](#what-metadata-store-is-for?)\n",
    ">>- [atrifacts Tables](#atrifacts-Tables)\n",
    ">>- [Contexts Tables](#Contexts-Tables)\n",
    ">>- [Executions Tables](#Executions-Tables)\n",
    ">- [Loding dataset from tf_records](#Loding-dataset-from-tf_records)\n",
    ">-[Configuration Options](#Configuration-Options)\n",
    ">>- [splitting](#splitting)\n",
    ">>- [If data is stored in spitted manner](#If-data-is-stored-in-spitted-manner)\n",
    ">>- [Span](#Span)\n",
    ">-[Add-ons](#Add-ons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-situation",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "This component of the pipeline is used to read data files or request the data for our pipeline run or from an external service (e.g., Google Cloud BigQuery) and outputs an artifact for the further step. Before passing the ingested dataset to the next component, we divide the available data into training and validation datasets (split ratio and no of splits are configurable) and then convert the datasets into TFRecord files containing the data represented as tf.Example data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'absl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.orchestration.experimental.interactive.interactive_context \\\n",
    "        import InteractiveContext\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-paper",
   "metadata": {},
   "source": [
    "## What is InteractiveContext?\n",
    "The notebook is also used as an orchestater to run the pipeline components manually. The InteractiveContext class will be used in notebooks which helps us to reviewed the components artifacts immediately.\n",
    "\n",
    "Once you have confirmed the full functionality of your pipeline Components, you can convert your interactive pipeline to a production-ready pipeline by orchestrating it with DataFlow, kubeflow etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-austria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_name = Config.PIPELINE_NAME\n",
    "base_root = os.path.split(os.getcwd())[0]\n",
    "pipeline_root = os.path.join(base_root, Config.PIPELINE_FOLDER)\n",
    "beam_args = [\n",
    "    '--runner=DirectRunner'\n",
    "]\n",
    "\n",
    "if not os.path.exists(pipeline_root):\n",
    "    os.makedirs(pipeline_root)\n",
    "\n",
    "\n",
    "context = InteractiveContext(pipeline_name = pipeline_name,\n",
    "                            pipeline_root = pipeline_root,\n",
    "                            beam_pipeline_args = beam_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, 'data', 'dataset1')\n",
    "\n",
    "print(*os.listdir(data_dir), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-stick",
   "metadata": {},
   "source": [
    "CsvExampleGen is used to read multiple csv data file from given direct and outputs data in TFRecords format (split no and ratio will be depends on the configuration given) which will be used by further compents\n",
    "\n",
    "\n",
    ">note:\n",
    "configuring split ratio and number, span patter is demonstrated  in 'Configuration Option' Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = external_input(data_dir)\n",
    "example_gen = CsvExampleGen(input = examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-shell",
   "metadata": {},
   "source": [
    "Below cell will run the component and shows the artifact and its property\n",
    "\n",
    "the metadata of the\n",
    "run will be shown in the Jupyter Notebook. The outputs of the component, highlighting the storage locations of the training and the evaluation\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-cuisine",
   "metadata": {},
   "source": [
    "DataIngestion compent with default configuration will create train and eval folder and the data will be split in 2:1 ration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-cycle",
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_gen_prop = example_gen.outputs['examples'].get()[0]\n",
    "\n",
    "print('Artifact Location: ')\n",
    "print(f'\\t {example_gen_prop.uri}')\n",
    "print()\n",
    "\n",
    "print('Files: ')\n",
    "print('\\t train')\n",
    "print(f'\\t\\t {os.listdir(os.path.join(example_gen_prop.uri, \"train\"))}')\n",
    "print('\\t eval')\n",
    "print(f'\\t\\t {os.listdir(os.path.join(example_gen_prop.uri, \"eval\"))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-accident",
   "metadata": {},
   "source": [
    "## Output of the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_names = eval(example_gen_prop.split_names)\n",
    "artifact = os.path.join(example_gen_prop.uri, split_names[0])\n",
    "files = [os.path.join(artifact, i) for i in os.listdir(artifact)]\n",
    "\n",
    "train = tf.data.TFRecordDataset(filenames = files, compression_type = 'GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train.take(1):\n",
    "    serialized_example = data.numpy()\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(serialized_example)\n",
    "    pp.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-interference",
   "metadata": {},
   "source": [
    "## what metadata store is for?\n",
    "\n",
    "The Metadata Store uses the following data model to record and retrieve metadata from the storage backend.\n",
    "\n",
    "- ArtifactType describes an artifact's type and its properties that are stored in the metadata store. You can register these types on-the-fly with the metadata store in code, or you can load them in the store from a serialized format. Once you register a type, its definition is available throughout the lifetime of the store.\n",
    "- An Artifact describes a specific instance of an ArtifactType, and its properties that are written to the metadata store.\n",
    "- An ExecutionType describes a type of component or step in a workflow, and its runtime parameters.\n",
    "- An Execution is a record of a component run or a step in an ML workflow and the runtime parameters. An execution can be thought of as an instance of an ExecutionType. Executions are recorded when you run an ML pipeline or step.\n",
    "- An Event is a record of the relationship between artifacts and executions. When an execution happens, events record every artifact that was used by the execution, and every artifact that was produced. These records allow for lineage tracking throughout a workflow. By looking at all events, MLMD knows what executions happened and what artifacts were created as a result. MLMD can then recurse back from any artifact to all of its upstream inputs.\n",
    "- A ContextType describes a type of conceptual group of artifacts and executions in a workflow, and its structural properties. For example: projects, pipeline runs, experiments, owners etc.\n",
    "- A Context is an instance of a ContextType. It captures the shared information within the group. For example: project name, changelist commit id, experiment annotations etc. It has a user-defined unique name within its ContextType.\n",
    "- An Attribution is a record of the relationship between artifacts and contexts.\n",
    "- An Association is a record of the relationship between executions and contexts.\n",
    "\n",
    "\n",
    "\n",
    "For the execution tracking of the artifacts and the lineage tracking capabilities (for example, telling which model or statistics correspond to which dataset or pipeline run), we’ve  to deal with Events, Contexts and Executions.\n",
    "\n",
    "- Events associate artifact_ids with execution_ids\n",
    "- Executions only track type_ids and timestamps\n",
    "- Contexts correlate type_ids with Pipeline runs and timestamp information\n",
    "\n",
    "The tables ExecutionProperty and ContextProperty contain extra data\n",
    "- ExecutionProperties contain input and output configuration passed to each component, along with pipeline and step root directories, and IO locations of artifacts.\n",
    "- ContextProperties associate context_ids with pipeline component names and timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_config = context.metadata_connection_config\n",
    "store = metadata_store.MetadataStore(connection_config)\n",
    "\n",
    "base_dir = connection_config.sqlite.filename_uri.split('metadata.sqlite')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-peter",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def display_properties(input):\n",
    "    data = defaultdict(list)\n",
    "    for artifact in input:\n",
    "        properties = artifact.properties\n",
    "        custom_properties = artifact.custom_properties\n",
    "        for key, value in properties.items():\n",
    "            data['artifact id'].append(artifact.id)\n",
    "            data['type_id'].append(artifact.type_id)\n",
    "            data['name'].append(key)\n",
    "            data['is_customproperty'].append(0)\n",
    "            data['value'].append(value.string_value)\n",
    "\n",
    "            \n",
    "        for key, value in custom_properties.items():\n",
    "            data['artifact id'].append(artifact.id)\n",
    "            data['type_id'].append(artifact.type_id)\n",
    "            data['name'].append(key)\n",
    "            data['is_customproperty'].append(1)\n",
    "            data['value'].append(value.string_value)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def display_types(types):\n",
    "    table = {'id': [], 'name': []}\n",
    "    for a_type in types:\n",
    "        table['id'].append(a_type.id)\n",
    "        table['name'].append(a_type.name.split('.')[-1])\n",
    "    return pd.DataFrame(data=table)\n",
    "\n",
    "def display_artifacts(store, artifacts):\n",
    "    table = defaultdict(list)\n",
    "    for a in artifacts:\n",
    "        table['artifact id'].append(a.id)\n",
    "        artifact_type = store.get_artifact_types_by_id([a.type_id])[0]\n",
    "        table['type'].append(artifact_type.name)\n",
    "        table['uri'].append(a.uri.replace(base_dir, './'))\n",
    "        table['create_time_since_epoch'].append(a.create_time_since_epoch)\n",
    "        table['last_update_time_since_epoch'].append(a.last_update_time_since_epoch)\n",
    "    return pd.DataFrame(data=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-thesis",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def display_context(store, artifacts):\n",
    "    table = defaultdict(list)\n",
    "    for a in artifacts:\n",
    "        table['artifact id'].append(a.id)\n",
    "        artifact_type = store.get_context_types_by_id([a.type_id])[0]\n",
    "        table['type'].append(artifact_type.name)\n",
    "        table['name'].append(a.name)\n",
    "        table['create_time_since_epoch'].append(a.create_time_since_epoch)\n",
    "        table['last_update_time_since_epoch'].append(a.last_update_time_since_epoch)\n",
    "    return pd.DataFrame(data=table)\n",
    "\n",
    "def display_executions(store, artifacts):\n",
    "    table = defaultdict(list)\n",
    "    for a in artifacts:\n",
    "        table['artifact id'].append(a.id)\n",
    "        artifact_type = store.get_execution_types_by_id([a.type_id])[0]\n",
    "        table['type'].append(artifact_type.name.split('.')[-1])\n",
    "        e_state = a.last_known_state\n",
    "        if e_state == 2:\n",
    "            table['last_known_state'].append('Running')\n",
    "        elif e_state == 3:\n",
    "            table['last_known_state'].append('Success')\n",
    "        else:\n",
    "            table['last_known_state'].append(e_state)\n",
    "        table['create_time_since_epoch'].append(a.create_time_since_epoch)\n",
    "        table['last_update_time_since_epoch'].append(a.last_update_time_since_epoch)\n",
    "    return pd.DataFrame(data=table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-singapore",
   "metadata": {},
   "source": [
    "### atrifacts Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_artifacts(store, store.get_artifacts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_types(store.get_artifact_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_properties(store.get_artifacts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-manchester",
   "metadata": {},
   "source": [
    "### Contexts Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_context(store, store.get_contexts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_types(store.get_context_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_properties(store.get_contexts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-spelling",
   "metadata": {},
   "source": [
    "### Executions Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_executions(store, store.get_executions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_properties(store.get_executions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_types(store.get_execution_types())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-victor",
   "metadata": {},
   "source": [
    "## Loding dataset from tf_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-ridge",
   "metadata": {},
   "source": [
    "Why TFRecord?\n",
    "\n",
    "If you are working with large datasets, using a binary file format for storage of your data can have a significant impact on the performance of your import pipeline and as a consequence on the training time of your model. Binary data takes up less space on disk, takes less time to copy and can be read much more efficiently from disk. This is especially true if your data is stored on spinning disks, due to the much lower read/write performance in comparison with SSDs.\n",
    "\n",
    "However, pure performance isn’t the only advantage of the TFRecord file format. It is optimized for use with Tensorflow in multiple ways. To start with, it makes it easy to combine multiple datasets and integrates seamlessly with the data import and preprocessing functionality provided by the library. Especially for datasets that are too large to be stored fully in memory this is an advantage as only the data that is required at the time (e.g. a batch) is loaded from disk and then processed. Another major advantage of TFRecords is that it is possible to store sequence data — for instance, a time series or word encodings — in a way that allows for very efficient and (from a coding perspective) convenient import of this type of data. \n",
    "\n",
    "[reference](https://www.quora.com/Is-it-especially-good-to-use-tfRecord-as-input-data-format-if-I-am-using-Keras-Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import ImportExampleGen\n",
    "\n",
    "root_dir = os.path.split(os.getcwd())[0]\n",
    "data_dir = os.path.join(root_dir, 'data', 'dataset2')\n",
    "\n",
    "print(*os.listdir(data_dir), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-costs",
   "metadata": {},
   "source": [
    "ImportExampleGen is used to load TFRecord files into the pipeline.\n",
    "\n",
    "It will make sense to load nlp data as TFRecord file were text corpora can snowball to a considerable size.To ingest such datasets efficiently, it is always recommend to converting the datasets as TFRecord or Apache Parquet representations. \n",
    "\n",
    "Image datasets from the image files has to be convert into TFRecord files, but\n",
    "not to decode the images. Any decoding of highly compressed images only increases\n",
    "the amount of disk space needed to store the intermediate tf.Example records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = external_input(data_dir)\n",
    "example_gen = ImportExampleGen(input=examples)\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-fountain",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_executions(store, store.get_executions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-theorem",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_properties(store.get_artifacts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-browser",
   "metadata": {},
   "source": [
    "## Configuration Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-houston",
   "metadata": {},
   "source": [
    "### splitting\n",
    "\n",
    "Later in our pipeline, we will want to evaluate our machine learning model during the\n",
    "training and test it during the model analysis step. Therefore, it is beneficial to split\n",
    "the dataset into the required subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.proto import example_gen_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-granny",
   "metadata": {},
   "source": [
    "Configuring output as train, test and eval with 6:2:2 ration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-mercy",
   "metadata": {},
   "source": [
    "The following cell is volentierly scripted to go under exception and complete the run succesfully after the exception accor.\n",
    "\n",
    "This is done to demonstrate the use of metadatastore when the execution of pipeline gone under some execption in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir = os.path.join(os.pardir, \"data/dataset\")\n",
    "\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=6), \n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=2), \n",
    "        example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=2)]\n",
    "                                                ))\n",
    "\n",
    "    examples = external_input(data_dir)\n",
    "    example_gen = CsvExampleGen(input=examples, output_config=output)\n",
    "    context.run(example_gen)\n",
    "except:\n",
    "    data_dir = os.path.join(os.pardir, \"data/dataset1\")\n",
    "\n",
    "    output = example_gen_pb2.Output(\n",
    "        split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=6), \n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=2), \n",
    "        example_gen_pb2.SplitConfig.Split(name='test', hash_buckets=2)]\n",
    "                                                ))\n",
    "\n",
    "    examples = external_input(data_dir)\n",
    "    example_gen = CsvExampleGen(input=examples, output_config=output)\n",
    "    context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "european-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Config.PIPELINE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amino-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../temp_\n",
      "├── CsvExampleGen\n",
      "│   └── examples\n",
      "│       ├── 1\n",
      "│       │   ├── eval\n",
      "│       │   │   └── data_tfrecord-00000-of-00001.gz\n",
      "│       │   └── train\n",
      "│       │       └── data_tfrecord-00000-of-00001.gz\n",
      "│       ├── 3\n",
      "│       ├── 4\n",
      "│       │   ├── eval\n",
      "│       │   │   └── data_tfrecord-00000-of-00001.gz\n",
      "│       │   ├── test\n",
      "│       │   │   └── data_tfrecord-00000-of-00001.gz\n",
      "│       │   └── train\n",
      "│       │       └── data_tfrecord-00000-of-00001.gz\n",
      "│       └── 6\n",
      "│           ├── eval\n",
      "│           │   └── data_tfrecord-00000-of-00001.gz\n",
      "│           └── train\n",
      "│               └── data_tfrecord-00000-of-00001.gz\n",
      "├── ExampleValidator\n",
      "│   └── anomalies\n",
      "│       └── 9\n",
      "│           ├── eval\n",
      "│           │   └── anomalies.pbtxt\n",
      "│           └── train\n",
      "│               └── anomalies.pbtxt\n",
      "├── ImportExampleGen\n",
      "│   └── examples\n",
      "│       ├── 2\n",
      "│       │   ├── eval\n",
      "│       │   │   └── data_tfrecord-00000-of-00001.gz\n",
      "│       │   └── train\n",
      "│       │       └── data_tfrecord-00000-of-00001.gz\n",
      "│       └── 5\n",
      "│           ├── eval\n",
      "│           │   └── data_tfrecord-00000-of-00001.gz\n",
      "│           ├── test\n",
      "│           │   └── data_tfrecord-00000-of-00001.gz\n",
      "│           └── train\n",
      "│               └── data_tfrecord-00000-of-00001.gz\n",
      "├── log\n",
      "│   ├── events.out.tfevents.1618466388.jagands-Lenovo-E41-25\n",
      "│   ├── events.out.tfevents.1618467009.jagands-Lenovo-E41-25\n",
      "│   └── events.out.tfevents.1618467810.jagands-Lenovo-E41-25\n",
      "├── metadata.sqlite\n",
      "├── SchemaGen\n",
      "│   └── schema\n",
      "│       └── 8\n",
      "│           └── schema.pbtxt\n",
      "├── StatisticsGen\n",
      "│   └── statistics\n",
      "│       └── 7\n",
      "│           ├── eval\n",
      "│           │   └── stats_tfrecord\n",
      "│           └── train\n",
      "│               └── stats_tfrecord\n",
      "├── tftransform_tmp\n",
      "│   ├── 1cb0d652a164443492ab65b0432884b5\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   ├── 3cb8be6beca04cb8af209491039760a0\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   ├── 439985cbefaf4293be8d881ad6d8c83d\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   ├── 578b538ecfc145c98637eb0ef78c6082\n",
      "│   │   ├── assets\n",
      "│   │   │   └── vocab_compute_and_apply_vocabulary_vocabulary\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   ├── 88c77025765b4e928025dc665cdc1a4d\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   ├── e3959758feae444babd57b83e4d08523\n",
      "│   │   ├── assets\n",
      "│   │   │   └── vocab_compute_and_apply_vocabulary_vocabulary\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── variables\n",
      "│   └── vocab_compute_and_apply_vocabulary_vocabulary\n",
      "└── Transform\n",
      "    ├── transformed_examples\n",
      "    │   └── 10\n",
      "    │       ├── eval\n",
      "    │       │   └── transformed_examples-00000-of-00001.gz\n",
      "    │       └── train\n",
      "    │           └── transformed_examples-00000-of-00001.gz\n",
      "    ├── transform_graph\n",
      "    │   └── 10\n",
      "    │       ├── metadata\n",
      "    │       │   └── schema.pbtxt\n",
      "    │       ├── transformed_metadata\n",
      "    │       │   ├── asset_map\n",
      "    │       │   └── schema.pbtxt\n",
      "    │       └── transform_fn\n",
      "    │           ├── assets\n",
      "    │           │   ├── vocab_compute_and_apply_vocabulary_1_vocabulary\n",
      "    │           │   ├── vocab_compute_and_apply_vocabulary_2_vocabulary\n",
      "    │           │   ├── vocab_compute_and_apply_vocabulary_3_vocabulary\n",
      "    │           │   ├── vocab_compute_and_apply_vocabulary_4_vocabulary\n",
      "    │           │   └── vocab_compute_and_apply_vocabulary_vocabulary\n",
      "    │           ├── saved_model.pb\n",
      "    │           └── variables\n",
      "    └── updated_analyzer_cache\n",
      "        └── 10\n",
      "            └── temp_-CsvExampleGen-examples-6-train-STAR-ac3d8a517faf8cfdca2d5a5dc22a4c678e19d3a794d9f65ddf1aa415ee1cf376\n",
      "                ├── 0-00000-of-00001.gz\n",
      "                ├── 1-00000-of-00001.gz\n",
      "                ├── 2-00000-of-00001.gz\n",
      "                ├── 3-00000-of-00001.gz\n",
      "                ├── 4-00000-of-00001.gz\n",
      "                ├── 5-00000-of-00001.gz\n",
      "                └── MANIFEST\n",
      "\n",
      "66 directories, 48 files\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$folder\"\n",
    "tree ../$1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-account",
   "metadata": {},
   "source": [
    "Exception run is marked with red color. you can find that last_known_state is marked as 'Running' using this you can trace the exception component and backtrack to find the reason for that happend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(s):\n",
    "    if s.last_known_state == 'Running':\n",
    "        return ['background-color: red']*5\n",
    "    else:\n",
    "        return ['background-color: white']*5\n",
    "\n",
    "execution = display_executions(store, store.get_executions())\n",
    "execution.style.apply(highlight, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_id = execution['artifact id'].loc[execution.last_known_state == 'Running'].values[0]\n",
    "\n",
    "def highlight(s):\n",
    "    if s['artifact id'] == artifact_id:\n",
    "        return ['background-color: lightblue']*5\n",
    "    elif s['artifact id'] == artifact_id + 1:\n",
    "        return ['background-color: lightgreen']*5\n",
    "    else:\n",
    "        return ['background-color: white']*5\n",
    "\n",
    "execution_prop = display_properties(store.get_executions())\n",
    "execution_prop = execution_prop.loc[(execution_prop['artifact id'] == artifact_id) | (execution_prop['artifact id'] == artifact_id+1)].sort_values(by=['name','artifact id'])\n",
    "execution_prop.style.apply(highlight, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-indonesia",
   "metadata": {},
   "source": [
    "### If data is stored in spitted manner\n",
    "\n",
    "In some situations, we have already generated the subsets of the datasets externally,\n",
    "and we would like to preserve these splits when we ingest the datasets. We can ach‐\n",
    "ieve this by providing an input configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_prop = example_gen.outputs['examples'].get()[0]\n",
    "\n",
    "shutil.copytree(example_gen_prop.uri, '../data/dataset3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.proto import example_gen_pb2\n",
    "\n",
    "root_dir = os.path.split(os.getcwd())[0]\n",
    "data_dir = os.path.join(root_dir, 'data', 'dataset3')\n",
    "\n",
    "input = example_gen_pb2.Input(splits=[\n",
    "example_gen_pb2.Input.Split(name='train', pattern='train/*'),\n",
    "example_gen_pb2.Input.Split(name='eval', pattern='eval/*'),\n",
    "example_gen_pb2.Input.Split(name='test', pattern='test/*')\n",
    "])\n",
    "\n",
    "examples = external_input(os.path.join(base_dir, data_dir))\n",
    "example_gen = ImportExampleGen(input=examples, input_config=input)\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_property = display_properties(store.get_executions())\n",
    "execution_property.loc[execution_property['artifact id'] == max(execution_property['artifact id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-proxy",
   "metadata": {},
   "source": [
    "### Span\n",
    "\n",
    "One of the significant use cases for machine learning pipelines is that we can update\n",
    "our machine learning models when new data becomes available. For this scenario,\n",
    "the ExampleGen component allows us to use spans. Think of a span as a snapshot of\n",
    "data. Every hour, day, or week, a batch extract, transform, load (ETL) process could\n",
    "make such a data snapshot and create a new span.\n",
    "A span can replicate the existing data records. As shown in the following, export-1\n",
    "contains the data from the previous export-0 as well as newly created records\n",
    "\n",
    "We can now specify the patterns of the spans. The input configuration accepts a\n",
    "{SPAN} placeholder, which represents the number (0, 1, 2, ...) shown in our folder\n",
    "structure. With the input configuration, the ExampleGen component now picks up\n",
    "the “latest” span. In our example, this would be the data available under folder\n",
    "export-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/dataset4/export-0\n",
    "mkdir -p ../data/dataset4/export-1\n",
    "mkdir -p ../data/dataset4/export-2\n",
    "\n",
    "file_l_count=$(wc -l < ../data/dataset1/consumer_complaints_with_narrative.csv)\n",
    "head -n $(( file_l_count/3 )) ../data/dataset1/consumer_complaints_with_narrative.csv >> ../data/dataset4/export-0/consumer_complaints_with_narrative_$(( file_l_count/3 )).csv\n",
    "head -n $(( file_l_count/2)) ../data/dataset1/consumer_complaints_with_narrative.csv >> ../data/dataset4/export-1/consumer_complaints_with_narrative_$(( file_l_count/2 )).csv\n",
    "cp ../data/dataset1/consumer_complaints_with_narrative.csv ../data/dataset4/export-2/consumer_complaints_with_narrative_$file_l_count.csv\n",
    "\n",
    "tree ../data/dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.split(os.getcwd())[0]\n",
    "data_dir = os.path.join(base_dir, \"data\", \"dataset4\")\n",
    "\n",
    "\n",
    "input = example_gen_pb2.Input(splits=[\n",
    "example_gen_pb2.Input.Split(pattern='export-{SPAN}/*')\n",
    "])\n",
    "examples = external_input(data_dir)\n",
    "example_gen = CsvExampleGen(input=examples, input_config=input)\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_prperties = display_properties(store.get_executions())\n",
    "temp_val = execution_prperties.loc[(execution_prperties['name'] == 'input_base') | \n",
    "                         (execution_prperties['name'] == 'span')]\n",
    "temp_val = temp_val.reset_index()\n",
    "temp_val.drop('index', axis = 1, inplace = True)\n",
    "temp_val = temp_val.sort_values(['artifact id', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-resort",
   "metadata": {},
   "source": [
    "you can find that the span for current run is stored as 2 which means that ExampleGen component automaticaly fetched the current datafile from the given folder based on pattern configured in input_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val.style.highlight_max(subset = ['value'],\n",
    "                       color = 'lightgreen', axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-boston",
   "metadata": {},
   "source": [
    "## Add-ons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-vision",
   "metadata": {},
   "source": [
    "### Ingesting Data from avro or parquest file format\n",
    "\n",
    "#### from Avro-serialized data\n",
    "\n",
    "```\n",
    "from tfx.components import FileBasedExampleGen\n",
    "from tfx.components.example_gen.custom_executors import avro_executor\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "examples = external_input(avro_dir_path)\n",
    "\n",
    "example_gen = FileBasedExampleGen(\n",
    "    input=examples,\n",
    "    executor_class=avro_executor.Executor)\n",
    "```\n",
    "\n",
    "####  from Parquet-serialized data\n",
    "\n",
    "```\n",
    "from tfx.components.example_gen.custom_executors import parquet_executor\n",
    "example_gen = FileBasedExampleGen(\n",
    "input=examples,\n",
    "executor_class=parquet_executor.Executor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-eleven",
   "metadata": {},
   "source": [
    "### Ingesting data from Data Base\n",
    "\n",
    "#### from bigquery database\n",
    "```\n",
    "from tfx.components import BigQueryExampleGen\n",
    "query = \"\"\"\n",
    "SELECT * FROM `<project_id>.<database>.<table_name>`\n",
    "\"\"\"\n",
    "example_gen = BigQueryExampleGen(query=query)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    ">Note:\n",
    "            In TFX versions greater than 0.22.0, the BigQueryExampleGen\n",
    "            component needs to be imported from tfx.extensions.goo\n",
    "            gle_cloud_big_query :\n",
    ">```\n",
    "from tfx.extensions.google_cloud_big_query.example_gen import component as big_query_example_gen_component\n",
    "big_query_example_gen_component.BigQueryExampleGen(query=query)\n",
    ">```\n",
    "\n",
    "#### from presto database\n",
    "```\n",
    "from proto import presto_config_pb2\n",
    "from presto_component.component import PrestoExampleGen\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM `<project_id>.<database>.<table_name>`\n",
    "\"\"\"\n",
    "presto_config = presto_config_pb2.PrestoConnConfig(\n",
    "host='localhost',\n",
    "port=8080)\n",
    "example_gen = PrestoExampleGen(presto_config, query=query)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "489px",
    "left": "165px",
    "top": "246px",
    "width": "258.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
